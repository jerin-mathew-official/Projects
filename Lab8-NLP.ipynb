{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a6fb99",
   "metadata": {},
   "source": [
    "# LAB 8 - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed2cc8c",
   "metadata": {},
   "source": [
    "### SIMILARITY & WSD-LESK IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326743d2",
   "metadata": {},
   "source": [
    "#### Name: Jerin Mathew\n",
    "#### Roll No: 2139455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3eb4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\JERIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c00f1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5579dca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.698309e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>my best wishes to everyone for a happy thanksg...</td>\n",
       "      <td>04-05-2009 13.54</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.701461e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>wishing everyone a very happy holiday season</td>\n",
       "      <td>04-05-2009 20.00</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.737480e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>08-05-2009 8.38</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.741161e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>08-05-2009 15.40</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.773561e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>12-05-2009 9.07</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.776420e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>Miss USA Tara Conner will not be fired - \"I've...</td>\n",
       "      <td>12-05-2009 14.21</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.786561e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/178...</td>\n",
       "      <td>Listen to an interview with Donald Trump discu...</td>\n",
       "      <td>13-05-2009 12.38</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.796477e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/179...</td>\n",
       "      <td>\"Strive for wholeness and keep your sense of w...</td>\n",
       "      <td>14-05-2009 11.30</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.806259e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/180...</td>\n",
       "      <td>Enter the \"Think Like A Champion\" signed book ...</td>\n",
       "      <td>15-05-2009 9.13</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.820624e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/182...</td>\n",
       "      <td>\"When the achiever achieves, it's not a platea...</td>\n",
       "      <td>16-05-2009 17.22</td>\n",
       "      <td>19</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               link  \\\n",
       "0  1.698309e+09  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1  1.701461e+09  https://twitter.com/realDonaldTrump/status/170...   \n",
       "2  1.737480e+09  https://twitter.com/realDonaldTrump/status/173...   \n",
       "3  1.741161e+09  https://twitter.com/realDonaldTrump/status/174...   \n",
       "4  1.773561e+09  https://twitter.com/realDonaldTrump/status/177...   \n",
       "5  1.776420e+09  https://twitter.com/realDonaldTrump/status/177...   \n",
       "6  1.786561e+09  https://twitter.com/realDonaldTrump/status/178...   \n",
       "7  1.796477e+09  https://twitter.com/realDonaldTrump/status/179...   \n",
       "8  1.806259e+09  https://twitter.com/realDonaldTrump/status/180...   \n",
       "9  1.820624e+09  https://twitter.com/realDonaldTrump/status/182...   \n",
       "\n",
       "                                             content              date  \\\n",
       "0  my best wishes to everyone for a happy thanksg...  04-05-2009 13.54   \n",
       "1       wishing everyone a very happy holiday season  04-05-2009 20.00   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L...   08-05-2009 8.38   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and...  08-05-2009 15.40   \n",
       "4  \"My persona will never be that of a wallflower...   12-05-2009 9.07   \n",
       "5  Miss USA Tara Conner will not be fired - \"I've...  12-05-2009 14.21   \n",
       "6  Listen to an interview with Donald Trump discu...  13-05-2009 12.38   \n",
       "7  \"Strive for wholeness and keep your sense of w...  14-05-2009 11.30   \n",
       "8  Enter the \"Think Like A Champion\" signed book ...   15-05-2009 9.13   \n",
       "9  \"When the achiever achieves, it's not a platea...  16-05-2009 17.22   \n",
       "\n",
       "   retweets  favorites mentions hashtags  \n",
       "0       510        917      NaN      NaN  \n",
       "1        34        267      NaN      NaN  \n",
       "2        13         19      NaN      NaN  \n",
       "3        11         26      NaN      NaN  \n",
       "4      1375       1945      NaN      NaN  \n",
       "5        29         28      NaN      NaN  \n",
       "6        15         16      NaN      NaN  \n",
       "7        18         27      NaN      NaN  \n",
       "8        15          9      NaN      NaN  \n",
       "9        19         47      NaN      NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:/ClassesMSC/DataSets/realdonaldtrump.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e968c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my best wishes to everyone for a happy thanksgiving'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['content'][0]\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f0991",
   "metadata": {},
   "source": [
    "# Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9586beb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my', 'best', 'wishes', 'to', 'everyone', 'for', 'a', 'happy', 'thanksgiving']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = nltk.word_tokenize(a)\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27cc3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'wishes', 'everyone', 'happy', 'thanksgiving']\n"
     ]
    }
   ],
   "source": [
    "#stop words in nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filter1 = [w for w in token1 if not w in stop_words]\n",
    "print(filter1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977a612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('best.n.01'),\n",
       " Synset('wish.n.01'),\n",
       " Synset('happy.a.01'),\n",
       " Synset('thanksgiving.n.01')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn1=[]\n",
    "for i in filter1:\n",
    "    ss = wn.synsets(i)\n",
    "    if ss:\n",
    "        syn1.append(ss[0])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "syn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e7d94c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wishing everyone a very happy holiday season'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = df['content'][1]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d786a4",
   "metadata": {},
   "source": [
    "# Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bf3570c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wishing', 'everyone', 'a', 'very', 'happy', 'holiday', 'season']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2 = nltk.word_tokenize(b)\n",
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5324d2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wishing', 'everyone', 'happy', 'holiday', 'season']\n"
     ]
    }
   ],
   "source": [
    "#stop words in nltk library\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filter2 = [w for w in token2 if not w in stop_words]\n",
    "print(filter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ae5d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('wish.n.01'),\n",
       " Synset('happy.a.01'),\n",
       " Synset('vacation.n.01'),\n",
       " Synset('season.n.01')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn2=[]\n",
    "for i in filter2:\n",
    "    ss = wn.synsets(i)\n",
    "    if ss:\n",
    "        syn2.append(ss[0])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "syn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bed0933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(syn1[2].path_similarity(syn2[1])) # both words are everyone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c411a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26666666666666666, 0.18181818181818182, 0.25, 0.2857142857142857, 1.0, 0.2, 0.26666666666666666, 0.3076923076923077, 0.2, 1.0, 0.18181818181818182, 0.2222222222222222, 0.23529411764705882, 0.15384615384615385, 0.5555555555555556, 0.625]\n"
     ]
    }
   ],
   "source": [
    "#calculating similarity score for two sentences\n",
    "score=[]\n",
    "for i in range(len(syn1)):\n",
    "    for j in range(len(syn2)):\n",
    "        score.append(syn1[i].wup_similarity(syn2[j])) \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a03a3b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37076839622795504\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0cb5a1",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "\n",
    "It can be assumed that the sentences are similar to each other by 37%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65263a1",
   "metadata": {},
   "source": [
    "# LESK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c64da03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db6e5eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('deposit.v.02') put into a bank account\n",
      "\n",
      "Synset('savings_bank.n.02') a container (usually with a slot in the top) for keeping money at home\n"
     ]
    }
   ],
   "source": [
    "a1= lesk(word_tokenize('The bank will not be accepting cash on Saturdays.'),'bank')\n",
    "print(a1,a1.definition())\n",
    "print()\n",
    "a2 = lesk(word_tokenize('The river overflowed the bank.'),'bank')\n",
    "print(a2,a2.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514daefe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
