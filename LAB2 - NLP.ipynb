{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c6ed96",
   "metadata": {},
   "source": [
    "# LAB 2\n",
    "\n",
    "## NLP - STOP WORD REMOVAL AND FREQUENCY COUNT\n",
    "\n",
    "## JERIN MATHEW\n",
    "\n",
    "## ROLL NO: 2139455"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dc6822",
   "metadata": {},
   "source": [
    "#### Execute a program to remove stop words and to count frequency of words after tokenization of a real time data set  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6225de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e910c",
   "metadata": {},
   "source": [
    "## importing Tweets related Donald Trump to Analyse and Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513da9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.698309e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/169...</td>\n",
       "      <td>Be sure to tune in and watch Donald Trump on L...</td>\n",
       "      <td>04-05-2009 13.54</td>\n",
       "      <td>510</td>\n",
       "      <td>917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.701461e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/170...</td>\n",
       "      <td>Donald Trump will be appearing on The View tom...</td>\n",
       "      <td>04-05-2009 20.00</td>\n",
       "      <td>34</td>\n",
       "      <td>267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.737480e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/173...</td>\n",
       "      <td>Donald Trump reads Top Ten Financial Tips on L...</td>\n",
       "      <td>08-05-2009 8.38</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.741161e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/174...</td>\n",
       "      <td>New Blog Post: Celebrity Apprentice Finale and...</td>\n",
       "      <td>08-05-2009 15.40</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.773561e+09</td>\n",
       "      <td>https://twitter.com/realDonaldTrump/status/177...</td>\n",
       "      <td>\"My persona will never be that of a wallflower...</td>\n",
       "      <td>12-05-2009 9.07</td>\n",
       "      <td>1375</td>\n",
       "      <td>1945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               link  \\\n",
       "0  1.698309e+09  https://twitter.com/realDonaldTrump/status/169...   \n",
       "1  1.701461e+09  https://twitter.com/realDonaldTrump/status/170...   \n",
       "2  1.737480e+09  https://twitter.com/realDonaldTrump/status/173...   \n",
       "3  1.741161e+09  https://twitter.com/realDonaldTrump/status/174...   \n",
       "4  1.773561e+09  https://twitter.com/realDonaldTrump/status/177...   \n",
       "\n",
       "                                             content              date  \\\n",
       "0  Be sure to tune in and watch Donald Trump on L...  04-05-2009 13.54   \n",
       "1  Donald Trump will be appearing on The View tom...  04-05-2009 20.00   \n",
       "2  Donald Trump reads Top Ten Financial Tips on L...   08-05-2009 8.38   \n",
       "3  New Blog Post: Celebrity Apprentice Finale and...  08-05-2009 15.40   \n",
       "4  \"My persona will never be that of a wallflower...   12-05-2009 9.07   \n",
       "\n",
       "   retweets  favorites mentions hashtags  \n",
       "0       510        917      NaN      NaN  \n",
       "1        34        267      NaN      NaN  \n",
       "2        13         19      NaN      NaN  \n",
       "3        11         26      NaN      NaN  \n",
       "4      1375       1945      NaN      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/ClassesMSC/DataSets/realdonaldtrump.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa6da2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.335200e+04</td>\n",
       "      <td>43352.000000</td>\n",
       "      <td>43352.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.418822e+17</td>\n",
       "      <td>6264.766908</td>\n",
       "      <td>26234.241788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.270437e+17</td>\n",
       "      <td>11120.363335</td>\n",
       "      <td>47705.445640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.698309e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.645315e+17</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.852815e+17</td>\n",
       "      <td>396.500000</td>\n",
       "      <td>369.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.076130e+17</td>\n",
       "      <td>10753.000000</td>\n",
       "      <td>45784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.273440e+18</td>\n",
       "      <td>302269.000000</td>\n",
       "      <td>835575.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id       retweets      favorites\n",
       "count  4.335200e+04   43352.000000   43352.000000\n",
       "mean   6.418822e+17    6264.766908   26234.241788\n",
       "std    3.270437e+17   11120.363335   47705.445640\n",
       "min    1.698309e+09       0.000000       0.000000\n",
       "25%    3.645315e+17      27.000000      30.000000\n",
       "50%    5.852815e+17     396.500000     369.000000\n",
       "75%    9.076130e+17   10753.000000   45784.000000\n",
       "max    1.273440e+18  302269.000000  835575.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36688545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Be sure to tune in and watch Donald Trump on L...\n",
       "1        Donald Trump will be appearing on The View tom...\n",
       "2        Donald Trump reads Top Ten Financial Tips on L...\n",
       "3        New Blog Post: Celebrity Apprentice Finale and...\n",
       "4        \"My persona will never be that of a wallflower...\n",
       "                               ...                        \n",
       "43347    Joe Biden was a TOTAL FAILURE in Government. H...\n",
       "43348    Will be interviewed on @ seanhannity tonight a...\n",
       "43349                           pic.twitter.com/3lm1spbU8X\n",
       "43350                           pic.twitter.com/vpCE5MadUz\n",
       "43351                           pic.twitter.com/VLlc0BHW41\n",
       "Name: content, Length: 43352, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = data['content']\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa13e7ea",
   "metadata": {},
   "source": [
    "### Word tokenization of the tweets column to segreagate the words in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e3627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens=nltk.word_tokenize(col.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b4aa375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Be', 'sure', 'to', 'tune', 'in', 'and', 'watch', 'Donald', 'Trump', 'on', 'Late', 'Night', 'with', 'David', 'Letterman', 'as', 'he', 'presents', 'the', 'Top', 'Ten', 'List', 'tonight']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf899a",
   "metadata": {},
   "source": [
    "### Since the word tokenization command includes punctuation marks in the words when they are tokenized , we use the WordPunctTokenizer to seperate words and punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e841ba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e95cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Puncttokenize=WordPunctTokenizer().tokenize(col.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea34ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Donald', 'Trump', 'will', 'be', 'appearing', 'on', 'The', 'View', 'tomorrow', 'morning', 'to', 'discuss', 'Celebrity', 'Apprentice', 'and', 'his', 'new', 'book', 'Think', 'Like', 'A', 'Champion']\n"
     ]
    }
   ],
   "source": [
    "print(Puncttokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c5360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
